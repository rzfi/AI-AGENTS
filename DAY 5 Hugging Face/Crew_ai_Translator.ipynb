{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yV2QCG1WVLsc"
      },
      "outputs": [],
      "source": [
        "#pip install langchain-groq langchain-groq\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg-P-Ew0VUZo"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZYtKiVtoVVCk"
      },
      "outputs": [],
      "source": [
        "llm = ChatGroq(\n",
        "    temperature=0.5,\n",
        "    model_name=\"llama3-8b-8192\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3wnJaS8vVRJW"
      },
      "outputs": [],
      "source": [
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Summarize the following text in a concise paragraph:\\n\\n{text}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VdoLkQyIVgbJ"
      },
      "outputs": [],
      "source": [
        "translate_prompt = PromptTemplate(\n",
        "    input_variables=[\"summary\", \"language\"],\n",
        "    template=\"Translate the following summary into {language}:\\n\\n{summary}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2n5LGqeVh-y",
        "outputId": "799f92a0-bb0b-4ee1-ab8e-f07330c7a5bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_15576\\4278470831.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  summarize_chain = LLMChain(llm=llm, prompt=summary_prompt)\n"
          ]
        }
      ],
      "source": [
        "summarize_chain = LLMChain(llm=llm, prompt=summary_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YNel70GkVia2"
      },
      "outputs": [],
      "source": [
        "translate_chain = LLMChain(llm=llm, prompt=translate_prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqB4oo7iVlY8"
      },
      "outputs": [],
      "source": [
        "def summarize_and_translate(text, target_language):\n",
        "    # Summarize\n",
        "    summary = summarize_chain.run(text)\n",
        "    print(\"üîç Summary:\")\n",
        "    print(summary)\n",
        "\n",
        "    # Translate\n",
        "    translation = translate_chain.run({\n",
        "        \"summary\": summary,\n",
        "        \"language\": target_language\n",
        "    })\n",
        "    print(\"\\nüåê Translation:\")\n",
        "    print(translation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwmBV45iVj5D",
        "outputId": "8a13822f-fdc1-4c78-da5d-04ce6d02a786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Summary:\n",
            "Artificial Intelligence (AI) has significantly impacted education, allowing teachers to focus on creative and interpersonal tasks by automating tasks such as personalized tutoring, grading, and content recommendations. While AI has brought numerous benefits, concerns persist regarding bias in algorithms and the protection of student data privacy.\n",
            "\n",
            "üåê Translation:\n",
            "‡Æï‡Æ≤‡Øç‡Æµ‡Æø ‡Æ§‡ØÅ‡Æ±‡Øà‡ÆØ‡Æø‡Æ≤‡Øç ‡Æï‡Æ≤‡Øç‡Æµ‡Æø ‡Æ®‡Æø‡Æ™‡Æ®‡Øç‡Æ§‡Æ©‡Øà‡Æï‡Æ≥‡Øç (AI) ‡Æ™‡ØÜ‡Æ±‡Øç‡Æ± ‡Æ™‡ØÜ‡Æ∞‡Æø‡ÆØ ‡Æ™‡Ææ‡Æ§‡Æø‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øà‡Æï‡Øç ‡Æï‡Øä‡Æ£‡Øç‡Æü‡ØÅ‡Æ≥‡Øç‡Æ≥‡Æ§‡ØÅ. ‡Æï‡Æ≤‡Øç‡Æµ‡Æø‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡Æü‡Øç‡Æü‡Æø‡ÆØ‡Æ≤‡Æø‡Æü‡Øç‡Æü ‡Æï‡Æ≤‡Øç‡Æµ‡Æø, ‡ÆÆ‡Æ§‡Æø‡Æ™‡Øç‡Æ™‡ØÜ‡Æ£‡Øç ‡Æµ‡Æï‡Æø‡Æ™‡Øç‡Æ™‡ØÅ, ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æü‡Æï‡Øç‡Æï ‡Æ™‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡ØÅ‡Æ∞‡Øà‡Æï‡Æ≥‡Øç ‡Æ™‡Øã‡Æ©‡Øç‡Æ± ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Øç‡Æï‡Æ≥‡Øà ‡Æ§‡Ææ‡Æ©‡Æø‡ÆØ‡Æï‡Øç‡Æï ‡ÆÆ‡ØÅ‡Æü‡Æø‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡Æé‡Æ©‡Øç‡Æ±‡Ææ‡Æ≤‡ØÅ‡ÆÆ‡Øç, ‡Æï‡Æ£‡Æø‡Æ©‡Æø ‡Æ®‡Æø‡Æ™‡Æ®‡Øç‡Æ§‡Æ©‡Øà‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡Æö‡ÆÆ‡Ææ‡Æ©‡Æ§‡Øç‡Æ§‡Øà‡ÆØ‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡Ææ‡Æ£‡Æµ‡Æ∞‡Øç‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡Æ§‡Æï‡Æµ‡Æ≤‡Øç ‡Æ™‡Øä‡Æ±‡ØÅ‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Øç‡Æï‡Ææ‡Æï ‡Æï‡Æµ‡Æ≤‡Øà‡Æï‡Æ≥‡Øç ‡Æâ‡Æ≥‡Øç‡Æ≥‡Æ©.\n"
          ]
        }
      ],
      "source": [
        "input_text = \"\"\"\n",
        "    Artificial Intelligence (AI) has revolutionized education in recent years.\n",
        "    From personalized tutoring systems and automated grading to intelligent content recommendations,\n",
        "    AI enables teachers to focus more on creative and interpersonal tasks.\n",
        "    However, concerns remain about bias in algorithms and student data privacy.\n",
        "    \"\"\"\n",
        "\n",
        "target_language = \"Tamil\"  # \"Hindi\", \"German\", \"Tamil\"\n",
        "summarize_and_translate(input_text, target_language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIYVj5nCV6wQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\moham\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# GUI Implementation\n",
        "import gradio as gr\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "\n",
        "# Initialize Groq LLaMA3 LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0.5,\n",
        "    model_name=\"llama3-8b-8192\"\n",
        ")\n",
        "\n",
        "# Prompt to summarize the input text\n",
        "summary_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Summarize the following text in a concise paragraph:\\n\\n{text}\"\n",
        ")\n",
        "\n",
        "# Prompt to translate the summary\n",
        "translate_prompt = PromptTemplate(\n",
        "    input_variables=[\"summary\", \"language\"],\n",
        "    template=\"Translate the following summary into {language}:\\n\\n{summary}\"\n",
        ")\n",
        "\n",
        "# Chains\n",
        "summarize_chain = LLMChain(llm=llm, prompt=summary_prompt)\n",
        "translate_chain = LLMChain(llm=llm, prompt=translate_prompt)\n",
        "\n",
        "# Main function for Gradio\n",
        "def summarize_and_translate_interface(text, language):\n",
        "    summary = summarize_chain.run(text)\n",
        "    translation = translate_chain.run({\n",
        "        \"summary\": summary,\n",
        "        \"language\": language\n",
        "    })\n",
        "    return summary, translation\n",
        "\n",
        "# Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=summarize_and_translate_interface,\n",
        "    inputs=[\n",
        "        gr.Textbox(lines=7, label=\"Enter Text to Summarize and Translate\"),\n",
        "        gr.Textbox(label=\"Target Language (e.g., French, Hindi, Tamil)\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üîç Summary\"),\n",
        "        gr.Textbox(label=\"üåê Translation\")\n",
        "    ],\n",
        "    title=\"üß† AI Text Summarizer & Translator\",\n",
        "    description=\"This app summarizes any input text and translates the summary into your chosen language using Groq's LLaMA3-8B model.\"\n",
        ")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "from langchain_groq import ChatGroq\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load API Key\n",
        "load_dotenv()\n",
        "\n",
        "# Setup Groq LLM\n",
        "llm = ChatGroq(\n",
        "    temperature=0.3,\n",
        "    model_name=\"llama3-8b-8192\"\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Agents\n",
        "# --------------------------\n",
        "\n",
        "# Researcher Agent: figures out the best algorithm and approach\n",
        "researcher = Agent(\n",
        "    role=\"Algorithm Researcher\",\n",
        "    goal=\"Determine the most optimal algorithm and data structure to solve coding problems\",\n",
        "    backstory=(\n",
        "        \"An expert in algorithm design, known for crafting high-performance solutions \"\n",
        "        \"for competitive coding. Has deep knowledge of time complexity and algorithm selection.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# Coder Agent: writes efficient Python code\n",
        "coder = Agent(\n",
        "    role=\"Python Code Generator\",\n",
        "    goal=\"Generate fast, optimized Python code that runs in under 10ms for given problems\",\n",
        "    backstory=(\n",
        "        \"A seasoned software engineer who writes highly optimized code, leveraging \"\n",
        "        \"advanced data structures and Python tricks to get minimal runtime on LeetCode.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Tasks\n",
        "# --------------------------\n",
        "\n",
        "# Task for researcher to determine optimal algorithm\n",
        "research_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the following LeetCode problem and determine the best algorithm to solve it \"\n",
        "        \"with time complexity ideally O(1), O(log n), or O(n). Consider edge cases.\\n\\n\"\n",
        "        \"Problem: {user_problem}\"\n",
        "    ),\n",
        "    expected_output=\"Detailed explanation of the best algorithm, time and space complexity, and pseudocode.\",\n",
        "    agent=researcher\n",
        ")\n",
        "\n",
        "# Task for coder to implement the solution\n",
        "code_task = Task(\n",
        "    description=(\n",
        "        \"Using the research summary, implement the optimal Python code for the following problem:\\n\\n\"\n",
        "        \"{user_problem}\\n\\n\"\n",
        "        \"Make sure the solution is correct, handles edge cases, and runs efficiently (<=10ms runtime).\"\n",
        "    ),\n",
        "    expected_output=\"Well-commented, fast, and correct Python code with no unnecessary overhead.\",\n",
        "    agent=coder\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# Crew Assembly\n",
        "# --------------------------\n",
        "\n",
        "def solve_leetcode_problem(problem_text: str):\n",
        "    # Inject problem into task descriptions\n",
        "    research_task.description = research_task.description.format(user_problem=problem_text)\n",
        "    code_task.description = code_task.description.format(user_problem=problem_text)\n",
        "\n",
        "    crew = Crew(\n",
        "        agents=[researcher, coder],\n",
        "        tasks=[research_task, code_task],\n",
        "        process=Process.sequential,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(\"\\nüß† Final Code Output:\\n\")\n",
        "    print(result)\n",
        "\n",
        "# --------------------------\n",
        "# Example Use\n",
        "# --------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    problem = \"\"\"\n",
        "    Given an array of integers nums and an integer target, return indices of the two numbers \n",
        "    such that they add up to target. You may assume that each input would have exactly one solution, \n",
        "    and you may not use the same element twice.\n",
        "\n",
        "    You can return the answer in any order.\n",
        "    \"\"\"\n",
        "    solve_leetcode_problem(problem)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
