{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf29f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_21948\\2613609350.py:58: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To find the latest research in LLMs, I need to search for recent research papers on the topic.\n",
      "\n",
      "Action: Web Search\n",
      "Action Input: \"latest research on large language models\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['The Llama 3.1 models were released in July 2024, including both a 405 billion and 70 billion parameter model. The most recent version is Llama ...', 'Research has shown that large language models (LLMs) tend to overemphasize information at the beginning and end of a document or ...', 'With advancements in LLMs across industries, Booth faculty are key figures leading broader application of language models, from finance to healthcare.', 'The performance of large language models is increasing exponentially, with potential to autonomously complete complex tasks in days rather than months.', 'As we look to 2025, large language models (LLMs) are at the center of a technological revolution that promises not only to transform industries ...', 'Large Language Models (LLMs) refer to large general-purpose language models that can be pre-trained and then fine-tuned for specific purposes.', 'We\\'re sharing two new papers that represent progress on the development of the \"microscope\", and the application of it to see new \"AI biology\".', 'Learn about large language models definition, use cases, examples, benefits, and challenges to get up to speed on generative AI.', 'As predicted by the Market Research Future report, the large language model (LLM) market in North America alone is expected to reach $105.5 billion by 2030.']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: From the search results, I can see that the latest research in LLMs is focused on their increasing performance, applications in various industries, and potential to transform industries. To summarize the latest research, I'll use the Structured Summary tool.\n",
      "\n",
      "Action: Structured Summary\n",
      "Action Input: \"latest research in large language models\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'title': 'Advancements in Large Language Models', 'summary': \"Recent research has focused on improving the efficiency and capabilities of large language models, including the development of more efficient architectures, better handling of long-range dependencies, and the ability to learn from few-shot examples. Notable examples include the Switch Transformer, which reduces computational cost, and the Meta AI's LLaMA, which achieves state-of-the-art results in few-shot learning. These advancements have paved the way for more widespread adoption of large language models in real-world applications.\"}\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: Now that I have a summary of the latest research in LLMs, I need to calculate how many tokens are needed for 3 million words.\n",
      "\n",
      "Action: Python REPL\n",
      "Action Input: `total_words = 3000000; average_words_per_token = 1.3; total_tokens = total_words / average_words_per_token; print(total_tokens)`\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m2307692.3076923075\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The latest research in LLMs is focused on improving their efficiency and capabilities, with notable examples including the Switch Transformer and Meta AI's LLaMA. To process 3 million words, approximately 2,307,692 tokens are needed, assuming an average of 1.3 words per token.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "ðŸ§  Final Answer:\n",
      " {'input': 'Find the latest research in LLMs and summarize it. Then calculate how many tokens are needed for 3 million words.', 'output': \"The latest research in LLMs is focused on improving their efficiency and capabilities, with notable examples including the Switch Transformer and Meta AI's LLaMA. To process 3 million words, approximately 2,307,692 tokens are needed, assuming an average of 1.3 words per token.\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "serpapi_api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama3-70b-8192\")\n",
    "\n",
    "search_tool = SerpAPIWrapper()\n",
    "\n",
    "python_tool = PythonREPLTool()\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"title\", description=\"Title of the research topic\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"Short summary in 2-3 lines\"),\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Give a short summary about: {topic}\\n{format_instructions}\",\n",
    "    input_variables=[\"topic\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "def structured_summary(topic: str) -> str:\n",
    "    prompt = prompt_template.format(topic=topic)\n",
    "    response = llm.invoke(prompt)\n",
    "    return output_parser.parse(response.content)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Web Search\",\n",
    "        func=search_tool.run,\n",
    "        description=\"Use this tool to search for recent research using SerpAPI\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Python REPL\",\n",
    "        func=python_tool.run,\n",
    "        description=\"Useful for calculations and logic\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Structured Summary\",\n",
    "        func=structured_summary,\n",
    "        description=\"Summarize a research topic in 2â€“3 lines with title\"\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "query = \"Find the latest research in LLMs and summarize it. Then calculate how many tokens are needed for 3 million words.\"\n",
    "\n",
    "result = agent.invoke(query)\n",
    "\n",
    "print(\"\\nðŸ§  Final Answer:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96283022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
